import CoreML
import Vision
import UIKit

func extractFeatureVector(from image: UIImage) async throws -> [Double]? {
    guard let cgImage = image.cgImage else { return nil }

    // Load mô hình ML
    let model = try MobileNetV2_FeatureExtractor(configuration: .init()).model
    let visionModel = try VNCoreMLModel(for: model)

    return try await withCheckedThrowingContinuation { continuation in
        let request = VNCoreMLRequest(model: visionModel) { request, error in
            if let error = error {
                continuation.resume(throwing: error)
                return
            }

            guard let result = request.results?.first as? VNCoreMLFeatureValueObservation,
                  let multiArray = result.featureValue.multiArrayValue else {
                continuation.resume(returning: nil)
                return
            }

            // Flatten multiArray → [Double]
            let vector = (0..<multiArray.count).map { multiArray[$0].doubleValue }
            continuation.resume(returning: vector)
        }

        request.imageCropAndScaleOption = .centerCrop  // Resize ảnh về 224x224 tự động

        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        do {
            try handler.perform([request])
        } catch {
            continuation.resume(throwing: error)
        }
    }
}
